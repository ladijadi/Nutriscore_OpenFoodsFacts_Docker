{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rapport du Projet de Déploiement en Conditions Réelles avec Docker\n",
    "\n",
    "1. Introduction\n",
    "\n",
    "Ce projet avait pour objectif de conteneuriser un modèle de machine learning existant et de le déployer via Docker, en exposant une API Flask pour effectuer des prédictions. Une partie importante du projet consistait à configurer un volume Docker pour stocker les requêtes et les prédictions, garantissant ainsi la persistance des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Étapes de Mise en Œuvre\n",
    "\n",
    "2.1. Conteneurisation du Modèle\n",
    "\n",
    "Téléchargement et préparation : Le modèle pré entraîné a été récupéré à partir d'un répertoire GitHub contenant un pipeline de prédiction.\n",
    "\n",
    "Structure de l’application Flask : Création d’un fichier app.py contenant une API Flask permettant de recevoir des requêtes POST et de répondre avec des prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dockerfile : Élaboration du fichier Docker pour construire l'image du projet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Utilisez une image de base Python\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# Définir le répertoire de travail dans le conteneur\n",
    "WORKDIR /app\n",
    "\n",
    "# Créez le volume pour /data\n",
    "VOLUME /data\n",
    "\n",
    "# Copier le dépôt GitHub cloné dans le répertoire de travail du conteneur\n",
    "COPY . .\n",
    "\n",
    "# Installer les dépendances\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Expose le port pour l'API\n",
    "EXPOSE 8000\n",
    "\n",
    "# Commande pour démarrer l'application\n",
    "CMD [\"python\", \"app.py\", \"--host='0.0.0.0'\",\"--port=8000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Configuration des Volumes\n",
    "\n",
    "Création d’un volume Docker :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "docker volume create prediction_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montage du volume lors de l’exécution du conteneur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "docker run -d -p 8000:8000 -v prediction_data:/data my-flask-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification de l'écriture des prédictions : Les prédictions et les données d’entrée sont écrites dans un fichier predictions.txt localisé dans le dossier monté /data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. Communication entre Conteneurs (Bonus)\n",
    "\n",
    "Connexion à une base de données Dockerisée : Mise en place d’un conteneur de base de données (par exemple, PostgreSQL ou SQLite).\n",
    "\n",
    "Tests de communication : Exécution de requêtes pour vérifier la bonne communication entre le conteneur Flask et la base de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Détails Techniques\n",
    "\n",
    "Code pour l’écriture dans un volume :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "@api.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    input_data = request.json\n",
    "    df = pd.DataFrame([input_data])\n",
    "    prediction = model_pipeline.predict(df)[0]\n",
    "    prediction_grade = prediction_mapping.get(prediction, prediction)\n",
    "    if not os.path.exists(\"/data\"):\n",
    "        os.makedirs(\"/data\")\n",
    "    with open(\"/data/predictions.txt\", \"a\") as f:\n",
    "        f.write(f\"Input: {input_data}, Prediction: {prediction_grade}\\n\")\n",
    "    return jsonify({\"prediction\": prediction_grade})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Problèmes Rencontrés et Solutions\n",
    "\n",
    "Erreur de port déjà utilisé : Correction en utilisant un autre port lors de l’exécution du conteneur (ex. : -p 5001:5000).\n",
    "\n",
    "Absence de répertoire pour le fichier de prédictions : Ajout de la création automatique du répertoire /data dans le code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Conclusion \n",
    "\n",
    "Ce projet a permis de déployer un modèle pré entraîné dans un environnement Docker, de configurer un volume pour sauvegarder les prédictions et de tester la communication avec une base de données. Cela renforce la compréhension du déploiement de services en conteneur et de la persistance des données dans un environnement isolé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Perspectives Futures\n",
    "\n",
    "Intégration d’un système de monitoring des prédictions.\n",
    "\n",
    "Automatisation du déploiement avec Docker Compose pour la gestion des conteneurs multiples."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
